{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad575a1f-ac45-4da7-9048-744aff37a492",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05760b43-1131-4e9a-a3e9-31c6a045edc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Automated Model Development with AutoML\n",
    "\n",
    "In this demo, we will demonstrate how to initiate AutoML experiments both through the user-friendly AutoML UI and programmatically using the AutoML API. When using the API, we will demonstrate some custom functionalities such as feature table integration and custom split ratios for train, validation and test.\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "*By the end of this demo, you will be able to:*\n",
    "\n",
    "* Start an AutoML experiment via the AutoML UI.\n",
    "\n",
    "* Start an AutoML experiment via the AutoML API.\n",
    "\n",
    "* Open and edit a notebook generated by AutoML.\n",
    "\n",
    "* Identify the best model generated by AutoML based on a given metric.\n",
    "\n",
    "* Modify the best model generated by AutoML.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6155f171-e471-44e3-9072-84da2ee120da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "1. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "   - In the drop-down, select **More**.\n",
    "   - In the **Attach to an existing compute resource** pop-up, select the first drop-down. You will see a unique cluster name in that drop-down. Please select that cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "1. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "1. Wait a few minutes for the cluster to start.\n",
    "1. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09c3d15e-78ff-45e3-aa4d-bcd7f154556e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d77e816-1c47-4ded-977f-840e2611c4e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Classroom Setup\n",
    "\n",
    "Before starting the demo, run the provided classroom setup script. This script will define configuration variables necessary for the demo. Execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5dbec38a-bbfb-4f8d-aee2-654e82a75d52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ac28bd1-67a7-4f89-b60f-4f223533e97f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Other Conventions:**\n",
    "\n",
    "Throughout this demo, we'll refer to the object `DA`. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a49aa030-999e-4c36-93d1-a03debdf5dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"User DB Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "176cdd8b-1ec7-480d-847c-78f5cb4b7e8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Prepare Data\n",
    "\n",
    "For this demonstration, we will utilize a fictional dataset from a Telecom Company, which includes customer information. This dataset encompasses **customer demographics**, including gender, as well as internet subscription details such as subscription plans and payment methods.\n",
    "\n",
    "A table with all features is already created for you.\n",
    "\n",
    "**Table name: `customer_churn`**\n",
    "\n",
    "To get started, execute the code block below and review the dataset schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6bd6527f-d244-4098-824c-1fb4256e5115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "churn_data = spark.sql(\"SELECT * FROM customer_churn\")\n",
    "display(churn_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c8d0a63-f6f6-4bf1-9901-f85e9343d5d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## AutoML Experiment with UI\n",
    "\n",
    "Databricks AutoML supports experimentation via the UI and the API. Thus, **in the first section of this demo we will demonstrate how to create an experiment using the UI**. Then, show how to create the same experiment via the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e41a54b8-5313-4828-b78d-e6f194309edd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Create AutoML Experiment\n",
    "\n",
    "Let's initiate an AutoML experiment to construct a baseline model for predicting customer churn. The target field for this prediction will be the `Churn` field.\n",
    "\n",
    "Follow these step-by-step instructions to create an AutoML experiment:\n",
    "\n",
    "1. Navigate to the **Experiments** section in Databricks.\n",
    "\n",
    "\n",
    "2. Click on **Classification**.\n",
    "\n",
    "  ![automl-create-experiment-v1](../Includes/images/automl-create-experiment-v2.png)\n",
    "\n",
    "3. Choose a cluster to execute the experiment.\n",
    "\n",
    "4. Select the **catalog > database > `customers_churn` table**, which was created in the previous step, as the input training dataset.\n",
    "\n",
    "5. Specify **`Churn`** as the prediction target.\n",
    "\n",
    "6. Deselect the **CustomerID** field as it's not needed as a feature.\n",
    "\n",
    "7. In the **Advanced Configuration** section, set the **Timeout** to **5 minutes**.\n",
    "\n",
    "8. Enter a name for your experiment. Let's enter `Churn_Prediction_AutoML_Experiment` as experiment name.\n",
    "\n",
    "![automl-input-fields-v1](../Includes/images/automl-input-fields-v1.png)\n",
    "\n",
    "**Optional Advanced Configuration:**\n",
    "\n",
    "![advanced-configurations-v1](../Includes/images/advanced-configurations-v1.png)\n",
    "\n",
    "- You have the flexibility to choose the **evaluation metric** and your preferred **training framework**.\n",
    "\n",
    "- If your dataset includes a timeseries field, you can define it when splitting the dataset.\n",
    "\n",
    "9. Click on **Start AutoML**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a2cf037-0002-4136-af5a-2e838b16151d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### View the Best Run\n",
    "\n",
    "Once the experiment is finished, it's time to examine the best run:\n",
    "\n",
    "1. Access the completed experiment in the **Experiments** section.\n",
    "\n",
    "2. Identify the best model run by evaluating the displayed **metrics**. Alternatively, you can click on **View notebook for best model** to access the automatically generated notebook for the top-performing model.\n",
    "\n",
    "![automl-completed-experiment-v1](../Includes/images/automl-completed-experiment-v2.png)\n",
    "\n",
    "3. Utilize the **Chart** tab to compare and contrast the various models generated during the experiment.\n",
    "\n",
    "You can find all details for the run  on the experiment page. There are different columns such as the framework used (e.g., `Scikit-Learn`, `XGBoost`), evaluation metrics (e.g., `Accuracy`, `F1 Score`), and links to the corresponding notebooks for each model. This allows you to make informed decisions about selecting the best model for your specific use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab562994-89b6-49e4-95a2-90e00089d836",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### View the Notebook\n",
    "\n",
    "####**Instruction for viewing the notebook of the best run:**\n",
    "\n",
    "\n",
    "\n",
    "+ **Click on the `\"View notebook for best model\"` link.**\n",
    "\n",
    "+ **Review the notebook that created the best model.**\n",
    "\n",
    "\n",
    "![automl-best-model-notebook-v1](../Includes/images/automl-best-model-notebook-v1.png)\n",
    "\n",
    "\n",
    "+ **Edit the notebook as required.**\n",
    "    + Identify the best model generated by AutoML based on a given metric and modify it as needed. The best model details, including the associated run ID, can be found in the MLflow experiment logs. Use the run ID to load the best model, make modifications, and save the modified model for deployment or further use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "faf3dd8f-5001-4c6c-be0a-40f82c78c123",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## AutoML Experiment with API\n",
    "\n",
    "In the previous section, we created an AutoML experiment using the user interface (UI) with basic functionalities. AutoML also supports advanced functionalities, such as **feature table integration** and **custom data split ratios**, which can enhance model performance and flexibility.\n",
    "\n",
    "In this section, we will utilize the AutoML API to create an experiment incorporating these advanced features. By leveraging the API, we gain greater control over the experiment's configuration, enabling the customization of feature inputs and the specification of data splitting strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a145c42a-aa6d-49c2-b499-b269b1e21049",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Set Features Table\n",
    "\n",
    "AutoML supports the use of feature tables as input. During setup, a feature table (**`customer_churn_features`**) is created. In this section, we will utilize this feature table during model training. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a448a61c-4895-4735-916e-a95440293d41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "features_table_path = f\"{DA.catalog_name}.{DA.schema_name}.customer_churn_features\"\n",
    "\n",
    "# View features tables\n",
    "display(spark.sql(f\"SELECT * FROM {features_table_path}\"))\n",
    "\n",
    "# Define the feature store lookups\n",
    "feauture_store_lookups = [\n",
    "    {\n",
    "        \"table_name\": features_table_path,\n",
    "        \"lookup_key\": [\"CustomerID\"]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b3c0fc8-915e-41a1-bf98-ad28832cde0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Set Custom Split - Random Split\n",
    "\n",
    "If you prefer AutoML to split the dataset with a different ratio than **the default 60:20:20**, you can create a new column in your dataset with the desired split assignments. This column **should contain the values \"train\", \"validate\", or \"test\"** to designate each row's role. When invoking the AutoML API, pass this column to the `split_col` parameter.\n",
    "\n",
    "This approach allows you to define custom data splits tailored to your specific requirements. Ensure that the `custom_split` column accurately reflects the intended distribution of your data into training, validation, and test sets. \n",
    "\n",
    "> _Example for understanding the code below: Consider the three values 0.5, 0.8, and 0.91 that are each mapped to three different rows. We will consider the row containing 0.5 as a _train_ data point, while 0.8 is considered a _validation_ data point and 0.91 as a _test_ data point. Basically, values in the interval [0, 0.79] belong to the training dataset, values between [0.8, 0.89] belong to the validation set, and values between [0.9, 1.0] belong to the test set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c55b5f1e-1471-4ae5-815c-2c2a55d82c80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, rand\n",
    "\n",
    "dataset = spark.read.table(\"customer_churn\")\n",
    "\n",
    "seed = 42 # define your seed here for reproduction\n",
    "train_ratio, validate_ratio, test_ratio = 0.8, 0.1, 0.1 # define your preferred ratios here\n",
    "\n",
    "dataset = dataset.withColumn(\"random\", rand(seed=seed))\n",
    "dataset = dataset.withColumn(\"custom_split\", when(dataset.random < train_ratio, \"train\")\n",
    "                                    .when(dataset.random < 1-test_ratio, \"validate\")\n",
    "                                    .otherwise(\"test\"))\n",
    "dataset = dataset.drop(\"random\")\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8f8ed7a-dc09-41b8-8426-47edca90e945",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " **Further Reading: Stratified Sampling with AutoML**\n",
    "\n",
    "Stratified sampling ensures that the distribution of a categorical variable (e.g., target labels) is preserved across the training, validation, and test sets. This is particularly useful when dealing with imbalanced datasets.\n",
    "\n",
    "1. **Identify the Stratification Column** – Choose a categorical variable to maintain proportions across dataset splits.\n",
    "\n",
    "2. **Compute Class Proportions** – Determine the distribution of each category in the dataset.\n",
    "\n",
    "3. **Calculate Sample Sizes** – Apply the desired split ratios to compute the exact number of records per class for each split.\n",
    "\n",
    "4. **Perform Stratified Sampling** – Split each category proportionally into training, validation, and test sets.\n",
    "\n",
    "5. **Assign Labels and Combine Splits** – Label the subsets accordingly and merge them into the final dataset.\n",
    "\n",
    "6. **Validate Class Distribution** – Ensure each split maintains the original class proportions.\n",
    "\n",
    "**Sample Code**\n",
    "\n",
    "```from pyspark.sql.functions import count, lit, col, round\n",
    "\n",
    "# Load dataset\n",
    "dataset = spark.read.table(\"customer_churn\")\n",
    "\n",
    "# Define stratification column\n",
    "stratify_col = \"Gender\"\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio, validate_ratio, test_ratio = 0.8, 0.1, 0.1\n",
    "seed = 42\n",
    "\n",
    "# Step 1: Compute class counts and original distribution\n",
    "class_counts = dataset.groupBy(stratify_col).agg(count(\"*\").alias(\"count\"))\n",
    "\n",
    "original_distribution = (\n",
    "    class_counts.withColumn(\"percentage\", round((col(\"count\") / dataset.count()) * 100, 2))\n",
    "    .withColumn(\"dataset\", lit(\"original\"))\n",
    ")\n",
    "\n",
    "# Step 2: Perform stratified sampling\n",
    "train_df = dataset.sampleBy(stratify_col, {row[stratify_col]: train_ratio for row in class_counts.collect()}, seed)\n",
    "validate_df = dataset.subtract(train_df).sampleBy(\n",
    "    stratify_col, {row[stratify_col]: validate_ratio / (validate_ratio + test_ratio) for row in class_counts.collect()}, seed\n",
    ")\n",
    "test_df = dataset.subtract(train_df).subtract(validate_df)\n",
    "\n",
    "# Assign split labels\n",
    "train_df = train_df.withColumn(\"custom_split\", lit(\"train\"))\n",
    "validate_df = validate_df.withColumn(\"custom_split\", lit(\"validate\"))\n",
    "test_df = test_df.withColumn(\"custom_split\", lit(\"test\"))\n",
    "\n",
    "# Combine datasets efficiently\n",
    "final_dataset = train_df.unionByName(validate_df).unionByName(test_df)\n",
    "\n",
    "# Step 4: Validate stratification with correct percentage calculation\n",
    "def validate_distribution(df, split_name):\n",
    "    total_split_count = df.count()\n",
    "    return (\n",
    "        df.groupBy(stratify_col)\n",
    "        .agg(count(\"*\").alias(\"count\"))\n",
    "        .withColumn(\"dataset\", lit(split_name))\n",
    "        .withColumn(\"percentage\", round((col(\"count\") / total_split_count) * 100, 2))\n",
    "    )\n",
    "\n",
    "# Compute distributions\n",
    "train_dist = validate_distribution(train_df, \"train\")\n",
    "validate_dist = validate_distribution(validate_df, \"validate\")\n",
    "test_dist = validate_distribution(test_df, \"test\")\n",
    "\n",
    "# **Ensure Schema Consistency Before Union**\n",
    "columns_order = [\"Gender\", \"count\", \"percentage\", \"dataset\"]\n",
    "\n",
    "original_distribution = original_distribution.select(*columns_order)\n",
    "train_dist = train_dist.select(*columns_order)\n",
    "validate_dist = validate_dist.select(*columns_order)\n",
    "test_dist = test_dist.select(*columns_order)\n",
    "\n",
    "# Combine all distributions (original + splits)\n",
    "distribution_comparison = original_distribution.unionByName(train_dist).unionByName(validate_dist).unionByName(test_dist)\n",
    "\n",
    "# Display the final distribution comparison\n",
    "display(distribution_comparison)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dfbe42d-abe9-4dbb-84b5-af880fbf6818",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Start an Experiment\n",
    "\n",
    "Now that we have **feature lookups** and **custom splits column** ready, we can continue to setup an AutoML experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "760617cf-cf55-4a90-98e6-83d64ebda0ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import automl\n",
    "from datetime import datetime\n",
    "\n",
    "automl_run = automl.classify(\n",
    "    dataset = dataset,\n",
    "    target_col = \"Churn\",\n",
    "    split_col = \"custom_split\",\n",
    "    exclude_cols = [\"CustomerID\"], # Exclude columns as needed\n",
    "    timeout_minutes = 5,\n",
    "    feature_store_lookups = feauture_store_lookups\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66dc7c07-775d-41bf-917d-09e8c8c589b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Search for the Best Run\n",
    "\n",
    "The search for the best run in this experiment, we need to first **get the experiment ID** and then **search for the runs** by experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b84c96e5-f57e-4553-9b3f-cffa9e8df47e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# Get the experiment path by experiment ID\n",
    "exp_path = mlflow.get_experiment(automl_run.experiment.experiment_id).name\n",
    "# Find the most recent experiment in the AutoML folder\n",
    "filter_string=f'name LIKE \"{exp_path}\"'\n",
    "automl_experiment_id = mlflow.search_experiments(\n",
    "  filter_string=filter_string,\n",
    "  max_results=1,\n",
    "  order_by=[\"last_update_time DESC\"])[0].experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03828863-1957-45e6-bea7-d817a516ee58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.entities import ViewType\n",
    "\n",
    "# Find the best run ...\n",
    "automl_runs_pd = mlflow.search_runs(\n",
    "  experiment_ids=[automl_experiment_id],\n",
    "  filter_string=f\"attributes.status = 'FINISHED'\",\n",
    "  run_view_type=ViewType.ACTIVE_ONLY,\n",
    "  order_by=[\"metrics.val_f1_score DESC\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "576847a4-a502-4bb3-be01-9f427a5839ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Print information about the best trial from the AutoML experiment.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef2616f9-84a7-449f-b7a9-6232aaf18c8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(automl_run.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d13f8b63-a400-4e65-b30d-d01672f7cf31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Explanation**\n",
    "\n",
    "\n",
    "- **`print(automl_run.best_trial)`**: This prints information about the best trial or run from the AutoML experiment.\n",
    "\n",
    "    - **Model:** Specifies the machine learning model that performed the best. \n",
    "\n",
    "    - **Model path:** The MLflow artifact URL of the model trained in this trial.\n",
    "\n",
    "    - **Preprocessors:** Description of the preprocessors run before training the model.\n",
    "\n",
    "    - **Training duration:** Displays the duration it took to train the best model.\n",
    "\n",
    "    - **Evaluation metric score:** Shows the value of the evaluation metric used to determine the best model. \n",
    "\n",
    "    - **Evaluation metric:** Score of primary metric, evaluated for the validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e6435a2-86e1-40de-94e7-665459144c0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Import notebooks for other runs in AutoML.**\n",
    "\n",
    "For classification and regression experiments, AutoML generated notebooks for data exploration and the best trial in your experiment are automatically imported to your workspace. Generated notebooks for other experiment trials are saved as MLflow artifacts on DBFS instead of auto-imported into your workspace. \n",
    "\n",
    "For all trials besides the best trial, the **`notebook_path`** and **`notebook_url`** in the TrialInfo Python API are not set. If you need to use these notebooks, you can manually import them into your workspace with the AutoML experiment UI or the **`automl.import_notebook`** Python API.\n",
    "\n",
    "**\uD83D\uDEA8 Notice:** `destination_path` takes Workspace as root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d0e32ca-b49e-40da-ac07-ac1b2bbc1dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the Destination path for storing the best run notebook\n",
    "destination_path = f\"/Users/{DA.username}/imported_notebooks/demo-3.1-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "\n",
    "# Get the path and url for the generated notebook\n",
    "result = automl.import_notebook(automl_run.trials[1].artifact_uri, destination_path)\n",
    "print(f\"The notebook is imported to: {result.path}\")\n",
    "print(f\"The notebook URL           : {result.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be86c5bf-1785-4617-ad2e-8205a2f08f35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "In this demo, we show how to use AutoML UI and AutoML API for creating classification model and how we can retrieve the best run and access the generated notebook, and how we can modify the parameters of the best model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1648accc-2912-4004-ba94-cb3bcd2d470e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "3.1 Demo - Automated Model Development with AutoML",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}