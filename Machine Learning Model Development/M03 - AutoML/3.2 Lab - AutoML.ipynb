{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23b7d352-23cb-490f-8586-69858dcffc16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4dee79ff-e1b7-4d43-8598-6b66efa39ac5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# LAB - AutoML\n",
    "\n",
    "Welcome to the AutoML Lab! In this lab, you will explore the capabilities of AutoML using the Databricks AutoMl UI and AutoML API. \n",
    "\n",
    "\n",
    "**Lab Outline:**\n",
    "\n",
    "In this lab, you will need to complete the following tasks;\n",
    "\n",
    "* **Task 1 :** Load data set.\n",
    "\n",
    "* **Task 2 :** Create a classification experiment using the AutoML UI.\n",
    "\n",
    "* **Task 3 :** Create a classification experiment with the AutoML API using a feature table.\n",
    "\n",
    "* **Task 4 :** Retrieve the best run and show the model URI.\n",
    "\n",
    "* **Task 5 :** Import the notebook for a run.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "939b1a8e-be77-4cd3-8e5c-2e578584647a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "1. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "   - In the drop-down, select **More**.\n",
    "   - In the **Attach to an existing compute resource** pop-up, select the first drop-down. You will see a unique cluster name in that drop-down. Please select that cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "1. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "1. Wait a few minutes for the cluster to start.\n",
    "1. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31722ca3-3b92-4008-a91a-e4658e69e9c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01e19b17-497e-4165-989c-fc87802a1cb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Classroom Setup\n",
    "\n",
    "Before starting the lab, run the provided classroom setup script. This script will define configuration variables necessary for the lab. Execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1d284a0-59f2-4c0a-8a1e-4c2e0aaba917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbe9e113-d47d-4fe7-847c-e99f9cbfd309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Other Conventions:**\n",
    "\n",
    "Throughout this demo, we'll refer to the object `DA`. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2213ebc-c4f0-4ed9-8acc-bcac50dd6a58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"User DB Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "573a3422-e468-453f-a960-498cde64abbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 1 : Load data set\n",
    "\n",
    "Load the dataset that will be used for the AutoML experiment.\n",
    "\n",
    "* Load and display the dataset where the table name is **`bank_loan`**.\n",
    "\n",
    "* Load and display the feature table where the feature table is **`bank_loan_features`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae4fccd5-81dc-4f79-8047-d361d07f42a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loan_data = <FILL_IN>\n",
    "display<FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ff93bad-8953-4f98-8808-cae1e6f440d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "loan_data = spark.sql(\"SELECT * FROM bank_loan\")\n",
    "display(loan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d59f6d6-04e0-4838-b8b5-c64a115eb728",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loan_features_data = <FILL_IN>\n",
    "display <FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e5925ae-d2c7-4a37-ad61-05e590f4e7c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "loan_features_data = spark.sql(\"SELECT * FROM bank_loan_features\")\n",
    "display(loan_features_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12ab53b8-2b2d-432e-9f97-99292b92c28c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 2: Create Classification Experiment Using AutoML UI\n",
    "\n",
    "Follow these steps to create an AutoML experiment using the  UI:\n",
    "\n",
    "  ***Step 1.*** Navigate to the **Experiments** section.\n",
    "\n",
    "  ***Step 2.*** Click on **Classification**.\n",
    "\n",
    "  ***Step 3.*** Choose a cluster for experiment execution.\n",
    "\n",
    "  ***Step 4.*** Select the input training dataset as **`catalog > database > bank_loan`**.\n",
    "\n",
    "  ***Step 5.*** Specify **`Personal_Loan`** as the prediction target.\n",
    "\n",
    "  ***Step 6.*** Deselect the **`ID`**, **`ZIP_Code`** field as it's not needed as a feature.\n",
    "\n",
    "  ***Step 7.*** Enter a name for your experiment, like `Bank_Loan_Prediction_AutoML_Experiment`.\n",
    "\n",
    "  ***Step 8.*** In the **Advanced Configuration** section, set the **Timeout** to **5 minutes**.\n",
    "\n",
    "  ***Step 9.*** Click on **Start AutoML**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d57765b2-705e-401a-b20f-7bb32c20abe7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 3: Create a Classification Experiment with the AutoML API\n",
    "\n",
    "Utilize the AutoML API to set up and run a classification experiment. Follow these steps:\n",
    "\n",
    "1. **Setting up the Experiment:**\n",
    "\n",
    "   - **Specify the Dataset:** Specify the dataset using the Spark table name, which is **`bank_loan`**.\n",
    "\n",
    "   - **Set Target Column:** Assign the target_col to the column you want to predict, which is **`Personal_Loan`**.\n",
    "\n",
    "   - **Adjust Exclude Columns:** Provide a list of columns to exclude from the modeling process after reviewing the displayed dataset.\n",
    "\n",
    "   - **Use features table** to be used as part of training. Feature table name: **`bank_loan_features`**.\n",
    "\n",
    "   - **Set Timeout Duration:** Determine the timeout_minutes for the AutoML experiment. such as `5` minutes.   \n",
    "\n",
    "2. **Running AutoML:**\n",
    "   - Use the AutoML API to explore various machine learning models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f846da8-3a8e-44d1-8863-dc738ce87a79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import automl\n",
    "from datetime import datetime\n",
    "\n",
    "features_table_path = f\"{DA.catalog_name}.{DA.schema_name}.bank_loan_features\"\n",
    "\n",
    "## Define the feature store lookups\n",
    "feauture_store_lookups = <FILL_IN> \n",
    "\n",
    "summary = automl.classify(\n",
    "    dataset = <FILL_IN>,\n",
    "    target_col = <FILL_IN>,\n",
    "    exclude_cols =<FILL_IN>, \n",
    "    timeout_minutes = <FILL_IN>,\n",
    "    feature_store_lookups = <FILL_IN>\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1ec9659-7e33-4c24-99ec-7f4c374ba23a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "from databricks import automl\n",
    "from datetime import datetime\n",
    "\n",
    "features_table_path = f\"{DA.catalog_name}.{DA.schema_name}.bank_loan_features\"\n",
    "\n",
    "# Define the feature store lookups\n",
    "feauture_store_lookups = [\n",
    "    {\n",
    "        \"table_name\": features_table_path,\n",
    "        \"lookup_key\": [\"ID\"]\n",
    "    }\n",
    "] \n",
    "\n",
    "summary = automl.classify(\n",
    "    dataset = loan_data,\n",
    "    target_col = \"Personal_Loan\",\n",
    "    exclude_cols = [\"ID\", \"ZIP_Code\"],  # Exclude columns as needed\n",
    "    timeout_minutes = 5,\n",
    "    feature_store_lookups = feauture_store_lookups\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "825a5368-b2e6-46f0-80ef-6898cae1e6bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 4: Retrieve the best run and show the model URI\n",
    "\n",
    "Identify the best model generated by AutoML based on a chosen metric. Retrieve information about the best run, including the model URI, to further explore and analyze the model.\n",
    " + Find the experiment id associated with your AutoML run experiment. \n",
    " + Define a search term to filter for runs. Adjust the search term based on the desired status, such as `FINISHED` or `ACTIVE`. \n",
    " + Specify the run view type to view only active runs or to view all runs.\n",
    " + Provide the metric you want to use for ordering  and Specify whether you want to order the runs in descending or ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2470f2e9-f265-41d8-b035-4dd3a0b13195",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "## Find the best run ...\n",
    "automl_runs_pd = mlflow.search_runs(\n",
    "  experiment_ids=<FILL_IN>,\n",
    "  filter_string=f<FILL_IN>,\n",
    "  run_view_type=<FILL_IN>,\n",
    "  order_by=<FILL_IN>\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a53c416-ce80-4716-99ff-23b6172d2721",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "import mlflow\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "## Find the best run ...\n",
    "automl_runs_pd = mlflow.search_runs(\n",
    "  experiment_ids=[summary.experiment.experiment_id], \n",
    "  filter_string=f\"attributes.status = 'FINISHED'\", \n",
    "  run_view_type=ViewType.ACTIVE_ONLY, \n",
    "  order_by=[\"metrics.val_f1_score DESC\"] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52eaf9bc-484f-4778-91bb-3d2cbcdc2502",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Print information about the best trial\n",
    "print(<FILL_IN>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84d8f5f8-d0c8-434e-aef2-4609c09a1484",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "## Print information about the best trial\n",
    "print(summary.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "971f8d74-ddb0-4537-a59e-35575fc42e58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Task 5: Import Notebook for a Run\n",
    "\n",
    "AutoML automatically generates the best run's notebook and makes it available for you. If you want to access to other runs' notebooks, you need to import them.\n",
    "\n",
    "In this task, you will import the **5th run's notebook** to the **`destination_path`**. \n",
    "\n",
    "Show the `url` and `path` of the imported notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86e3e0e0-6213-4b9d-9cdf-e35859414fa1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "destination_path = f\"/Users/{DA.username}/imported_notebooks/lab.3-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "\n",
    "## Get the path and url for the generated notebook\n",
    "result = <FILL_IN>\n",
    "print(result.path)\n",
    "print(result.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dcca5371-f079-4d92-95e9-76d941d8c122",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "destination_path = f\"/Users/{DA.username}/imported_notebooks/lab.3-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "\n",
    "## Get the path and url for t\n",
    "# he generated notebook\n",
    "result = automl.import_notebook(summary.trials[1].artifact_uri, destination_path)\n",
    "print(result.path)\n",
    "print(result.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6201f3e9-c01b-4a92-b411-eae0a423d17b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lab, you got hands-on with Databricks AutoML. You started by loading a dataset and creating a classification experiment using the AutoMl UI and AutoML API. You then learned how to summarize the best model by applying specific filters and explored the process of retrieving the best model along with its Model URI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be5d3412-9a45-4bf2-8d75-a42e3ebf7f63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "3.2 Lab - AutoML",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}