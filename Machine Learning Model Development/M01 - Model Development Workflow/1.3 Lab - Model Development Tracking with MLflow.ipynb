{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "688966d7-e51b-4e7b-9646-6ee505483f42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e3ec039-c536-490a-a1b3-227e3c2c3c4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# LAB - Model Development Tracking with **MLflow**\n",
    "\n",
    "In this lab, you will learn how to leverage MLflow to track and manage your model development process. First, you'll load data from a feature table and create train/test splits. Next, you'll train a classification model and track its training process using MLflow. Although MLflow supports autologging of metadata and artifacts, you will manually log parameters and artifacts to gain hands-on experience with its logging API.\n",
    "\n",
    "\uD83D\uDCCC **Note:** In previous demos, we covered both supervised and unsupervised model training. In this lab, however, **you will focus exclusively on fitting and tracking a supervised model.**\n",
    "\n",
    "**Lab Outline:**\n",
    "\n",
    "- **Task 1:** Load the dataset from the feature store table.\n",
    "\n",
    "- **Task 2:** Define the model hyperparameters.\n",
    "\n",
    "- **Task 3:** Track the model using MLflow.\n",
    "\n",
    "- **Task 4:** Log a custom figure.\n",
    "\n",
    "- **Task 5:** Review the model details via the MLflow Experiment runs UI.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "013adf59-1354-4b12-8c04-805638b00ae6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "1. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "   - In the drop-down, select **More**.\n",
    "   - In the **Attach to an existing compute resource** pop-up, select the first drop-down. You will see a unique cluster name in that drop-down. Please select that cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "1. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "1. Wait a few minutes for the cluster to start.\n",
    "1. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2e2c039-6235-4ccc-bc16-84ec89e03ef4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfe45cf9-2112-4caf-bde4-7935c7e26a21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Classroom Setup\n",
    "\n",
    "Before starting the lab, run the provided classroom setup scripts. \n",
    "\n",
    "**\uD83D\uDCCC Note:** In this lab you will register MLflow models with Unity Catalog. Therefore, you will need to run the next code block to **set model registry URI to UC**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eed271b1-cb38-4302-b14f-db67e8d95a7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install --upgrade 'mlflow-skinny[databricks]'\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cb91320-74aa-449b-b46c-cea1d82bdcf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next, this script will define configuration variables necessary for the demo. Execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "262c97d1-3904-499e-bfc3-6e7b7b6c3787",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9adec717-0ec1-456d-a0de-9ffdea2f3d87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Other Conventions:**\n",
    "\n",
    "Throughout this demo, we'll refer to the object `DA`. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7cb2d380-e4a5-4357-bc82-a9e56b0e2d43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"User DB Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d98be66a-2ea1-4b39-8bab-6afa37976fc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 1 - Load Dataset from Feature Store Table\n",
    "\n",
    "Use the feature store to load a dataset from a specific table.\n",
    "   - **Load Dataset:** Utilize MLflow's `load_delta` function to seamlessly retrieve and load the dataset from the Feature Store table named **`\"telco\"`** in the specified catalog and schema `(\"DA.catalog_name\" and \"DA.schema_name\")`. \n",
    "   - Convert dataset to `pandas` dataframe and explore the loaded dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "921d625e-0fcf-4304-b3ba-d2577d483669",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f352c0f3-3ed9-4285-b0a1-8a9477367030",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Import the necessary library for MLflow\n",
    "import mlflow\n",
    "\n",
    "## Load the feature dataset using mlflow.data\n",
    "feature_dataset = mlflow.<FILL_IN>(\n",
    "    table_name=<FILL_IN>,\n",
    "    name=<FILL_IN>\n",
    ")\n",
    "\n",
    "## convert the dataset to pandas df and drop the customerID column\n",
    "feature_data_pd = <FILL_IN>\n",
    "\n",
    "## Convert all feature_data_pd columns to float\n",
    "feature_data_pd = feature_data_pd.astype(float)\n",
    "\n",
    "## inspect final dataset\n",
    "display(<FILL_IN>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "667c71c1-0f3a-448b-b9db-89709733ea4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "## Import the necessary library for MLflow\n",
    "import mlflow\n",
    "\n",
    "## Load the feature dataset using mlflow.data\n",
    "feature_dataset = mlflow.data.load_delta(\n",
    "    table_name=f\"{DA.catalog_name}.{DA.schema_name}.telco\",\n",
    "    name=\"telco\"\n",
    ")\n",
    "\n",
    "## convert the dataset to pandas df and drop the customerID column\n",
    "feature_data_pd = feature_dataset.df.drop(\"customerID\").toPandas()\n",
    "\n",
    "## Convert all feature_data_pd columns to float\n",
    "feature_data_pd = feature_data_pd.astype(float)\n",
    "\n",
    "## inspect final dataset\n",
    "display(feature_data_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81c7fe43-4740-4a1b-8a5e-b54b8e9960fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Train / Test Split\n",
    "\n",
    "Split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84839d67-2f0a-4f15-b1f0-4f7bf7800c47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "import mlflow.sklearn  # For MLflow integration\n",
    "from sklearn.model_selection import train_test_split  # For splitting the dataset into training and testing sets\n",
    "\n",
    "## Split the dataset into training and testing sets\n",
    "target_col = <FILL_IN>\n",
    "X_all = <FILL_IN>\n",
    "y_all = <FILL_IN>\n",
    "X_train, X_test, y_train, y_test = <FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "698952ae-a8cf-4298-8017-bbf2f175f204",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "## Import necessary libraries\n",
    "import mlflow.sklearn  # For MLflow integration\n",
    "from sklearn.model_selection import train_test_split  # For splitting the dataset into training and testing sets\n",
    "\n",
    "## Split the dataset into training and testing sets\n",
    "target_col = \"Churn\"\n",
    "X_all = feature_data_pd.drop(labels=target_col, axis=1)\n",
    "y_all = feature_data_pd[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee8a024b-16fa-4634-84c3-ee5561f6646d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 2 - Define Model Hyperparameters\n",
    "\n",
    "In this lab, you will train a classification model. In this task define parameters for a Decision Tree Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7329a967-4f5b-4d51-ad4b-b67b0e074ca4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Define Decision Tree Classifier parameters\n",
    "dtc_params = {\n",
    "  'criterion': <FILL_IN>,\n",
    "  'max_depth': <FILL_IN>,\n",
    "  'min_samples_split': <FILL_IN>,\n",
    "  'min_samples_leaf': <FILL_IN>\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03aab934-ed41-4930-9b6e-b1b79e267b17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "## Define Decision Tree Classifier parameters\n",
    "dtc_params = {\n",
    "    'criterion': 'gini',\n",
    "    'max_depth': 50,\n",
    "    'min_samples_split': 20,\n",
    "    'min_samples_leaf': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f7e5b8f-ce59-4a91-9daf-c4320ff35281",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Task 3 - Track the Model Development  with MLflow\n",
    "\n",
    "Initialize an MLflow run.\n",
    "   - **Initialize MLflow Run:** Start an MLflow run to track the model development process. This allows for systematic recording of parameters, metrics, and artifacts associated with the model.\n",
    "\n",
    "   - **Logging Model Details:** Utilize MLflow tracking to log essential information about the model, including parameters, metrics, and other relevant artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89691f43-fe22-4eb9-8cc4-ec496b52f08a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13e8b880-6462-44f3-b882-a2d6b77947e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "## set the path for mlflow experiment\n",
    "mlflow.set_experiment(f\"/Users/{DA.username}/LAB-1-Model-Development-Tracking-with-MLflow\")\n",
    "\n",
    "## Turn off autologging as we want to log the model manually\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "## Start an MLFlow run\n",
    "with mlflow.start_run(run_name=\"Model Developing Tracking with MLflow Lab\") as run:\n",
    "   # Log the dataset\n",
    "   mlflow.log_input(feature_dataset, context=\"source\")\n",
    "   mlflow.log_input(mlflow.data.from_pandas(<FILL_IN>, source=feature_dataset.source), context=\"training\")\n",
    "   mlflow.log_input(mlflow.data.from_pandas(<FILL_IN> source=feature_dataset.source), context=\"test\")\n",
    "\n",
    "   ## Log parameters\n",
    "   mlflow.log_params(<FILL_IN>)\n",
    "\n",
    "   ## Fit the model\n",
    "   dtc = DecisionTreeClassifier(<FILL_IN>)\n",
    "   dtc_mdl = dtc.fit(<FILL_IN>)\n",
    "\n",
    "   ## Define model signature\n",
    "   signature = infer_signature(X_all, y_all)\n",
    "    \n",
    "   ## Log the model\n",
    "   ## Define the model name based on the feature store catalog and schema\n",
    "   model_name = f\"{DA.catalog_name}.{DA.schema_name}.churnmodel\"\n",
    "   mlflow.sklearn.log_model(\n",
    "       sk_model=<FILL_IN>,\n",
    "       artifact_path=\"model-artifacts\",\n",
    "       signature=<FILL_IN>,\n",
    "       registered_model_name=<FILL_IN>\n",
    "   )\n",
    "\n",
    "   ## Evaluate on the training set\n",
    "   y_pred_train = <FILL_IN>\n",
    "   mlflow.log_metric(\"train_accuracy\", <FILL_IN>)\n",
    "   mlflow.log_metric(\"train_precision\", <FILL_IN>)\n",
    "   mlflow.log_metric(\"train_recall\", <FILL_IN>)\n",
    "   mlflow.log_metric(\"train_f1\", <FILL_IN>)\n",
    "\n",
    "   ## Evaluate on the test set\n",
    "   y_pred_test = dtc_mdl.predict(X_test)\n",
    "   mlflow.log_metric(\"test_accuracy\", <FILL_IN>)\n",
    "   mlflow.log_metric(\"test_precision\", <FILL_IN>)\n",
    "   mlflow.log_metric(\"test_recall\", <FILL_IN>)\n",
    "   mlflow.log_metric(\"test_f1\", <FILL_IN>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c83219b-76ee-4281-a1b4-d8967d70975f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "## set the path for mlflow experiment\n",
    "mlflow.set_experiment(f\"/Users/{DA.username}/LAB-1-Model-Development-Tracking-with-MLflow\")\n",
    "\n",
    "## Turn off autologging as we want to log the model manually\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "## Start an MLFlow run\n",
    "with mlflow.start_run(run_name=\"Model Developing Tracking with MLflow Lab\") as run:\n",
    "    # Log the dataset\n",
    "    mlflow.log_input(feature_dataset, context=\"source\")\n",
    "    mlflow.log_input(mlflow.data.from_pandas(X_train, source=feature_dataset.source), context=\"training\")\n",
    "    mlflow.log_input(mlflow.data.from_pandas(X_test, source=feature_dataset.source), context=\"test\")\n",
    "\n",
    "    ## Log parameters\n",
    "    mlflow.log_params(dtc_params)\n",
    "\n",
    "    ## Fit the model\n",
    "    dtc = DecisionTreeClassifier(**dtc_params)\n",
    "    dtc_mdl = dtc.fit(X_train, y_train)\n",
    "\n",
    "    ## Define model signature\n",
    "    signature = infer_signature(X_all, y_all)\n",
    "   \n",
    "    ## Log the model\n",
    "    ## Define the model name based on the feature store catalog and schema\n",
    "    model_name = f\"{DA.catalog_name}.{DA.schema_name}.churnmodel\"\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=dtc_mdl,\n",
    "        artifact_path=\"model-artifacts\",\n",
    "        signature=signature,\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "\n",
    "    ## Evaluate on the training set\n",
    "    y_pred_train = dtc_mdl.predict(X_train)\n",
    "    mlflow.log_metric(\"train_accuracy\", accuracy_score(y_train, y_pred_train))\n",
    "    mlflow.log_metric(\"train_precision\", precision_score(y_train, y_pred_train))\n",
    "    mlflow.log_metric(\"train_recall\", recall_score(y_train, y_pred_train))\n",
    "    mlflow.log_metric(\"train_f1\", f1_score(y_train, y_pred_train))\n",
    "\n",
    "    ## Evaluate on the test set\n",
    "    y_pred_test = dtc_mdl.predict(X_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", accuracy_score(y_test, y_pred_test))\n",
    "    mlflow.log_metric(\"test_precision\", precision_score(y_test, y_pred_test))\n",
    "    mlflow.log_metric(\"test_recall\", recall_score(y_test, y_pred_test))\n",
    "    mlflow.log_metric(\"test_f1\", f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca111cf8-ae03-4d0a-ae92-b22fc2fd2449",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 4 - Log Custom Figure\n",
    "\n",
    "**Log Custom Figure/Visualization:** Include the logging of a custom figure, such as a confusion matrix or any relevant visualization, to further illustrate the model's behavior. This visual representation can be valuable for model evaluation and interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "522d53ac-e615-43dd-97ed-2af9a44b6e9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Import necessary libraries for creating and displaying a confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from mlflow.client import MlflowClient\n",
    "client = MlflowClient()\n",
    "\n",
    "## Compute the confusion matrix\n",
    "cm = confusion_matrix(<FILL_IN>)\n",
    "\n",
    "## Create a figure object and axes for the confusion matrix plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "## Create a ConfusionMatrixDisplay object with the computed confusion matrix\n",
    "disp = ConfusionMatrixDisplay(<FILL_IN>)\n",
    "\n",
    "## Plot the confusion matrix using the created axes and specified color map\n",
    "disp.plot(<FILL_IN>)\n",
    "\n",
    "## Set the title of the plot\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "## Log the confusion matrix figure to MLflow\n",
    "client.log_figure(<FILL_IN>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51484355-4f6e-4a44-ab53-8a17a645d000",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "## Import necessary libraries for creating and displaying a confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from mlflow.client import MlflowClient\n",
    "client = MlflowClient()\n",
    "\n",
    "## Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test, labels=[1, 0])\n",
    "\n",
    "## Create a figure object and axes for the confusion matrix plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "## Create a ConfusionMatrixDisplay object with the computed confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[1, 0])\n",
    "\n",
    "## Plot the confusion matrix using the created axes and specified color map\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "\n",
    "## Set the title of the plot\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "## Log the confusion matrix figure to MLflow\n",
    "client.log_figure(run.info.run_id, figure=fig, artifact_file=\"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07c86ecd-8487-4ffc-ad48-b485c68059a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 5 - Review model details via the UI\n",
    "To review the model details via the MLflow UI in the Experiment runs, follow these steps:\n",
    "\n",
    "+ Step 1: Go to the \"Experiments\" Section\n",
    "\n",
    "+ Step 2: Locate Your Experiment\n",
    "\n",
    "+ Step 3: Review Run Details\n",
    "\n",
    "+ Step 4: Reviewing Artifacts and Model metrics\n",
    "\n",
    "+ Step 5: Viewing Confusion Matrix Image\n",
    "\n",
    "+ Step 6: Retrieve Model Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8adea787-00ae-4c1b-88eb-cffbc41255d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "\n",
    "In conclusion, this lab showcased the effectiveness of MLflow in seamlessly managing the model development process. Leveraging MLflow's features, such as experiment tracking, custom metric logging, and artifact storage, enhances collaboration and ensures reproducibility. The ability to review model details through the MLflow UI provides valuable insights into model performance and aids in making informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "106ba4f9-f085-42f3-82d9-2eca833ac497",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "1.3 Lab - Model Development Tracking with MLflow",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}